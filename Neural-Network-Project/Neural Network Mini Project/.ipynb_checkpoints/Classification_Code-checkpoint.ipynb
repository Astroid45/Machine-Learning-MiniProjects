{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "77016c6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Ignoring invalid distribution -andas (/Users/hunglinh/opt/anaconda3/lib/python3.9/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -andas (/Users/hunglinh/opt/anaconda3/lib/python3.9/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: wget in /Users/hunglinh/opt/anaconda3/lib/python3.9/site-packages (3.2)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -andas (/Users/hunglinh/opt/anaconda3/lib/python3.9/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -andas (/Users/hunglinh/opt/anaconda3/lib/python3.9/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -andas (/Users/hunglinh/opt/anaconda3/lib/python3.9/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -andas (/Users/hunglinh/opt/anaconda3/lib/python3.9/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install wget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "72e0431c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import traceback\n",
    "from pdb import set_trace\n",
    "import sys\n",
    "import numpy as np\n",
    "from abc import ABC, abstractmethod\n",
    "import traceback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e01c103c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from util.timer import Timer\n",
    "from util.data import split_data, dataframe_to_array, binarize_classes\n",
    "from util.metrics import accuracy\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from datasets.MNISTDataset import MNISTDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9417f68",
   "metadata": {},
   "source": [
    "Your Name: **type your name here**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "687372f2",
   "metadata": {},
   "source": [
    "# Understand MNIST Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff523089",
   "metadata": {},
   "source": [
    "![](https://camo.githubusercontent.com/01c057a753e92a9bc70b8c45d62b295431851c09cffadf53106fc0aea7e2843f/687474703a2f2f692e7974696d672e636f6d2f76692f3051493378675875422d512f687164656661756c742e6a7067)\n",
    "The dataset you'll be using for this project is the famous [MNIST](https://en.wikipedia.org/wiki/MNIST_database) dataset which contains images of handwritten digits 0 through 9. There are 60,000 images included in the dataset and each image is a gray scale image of size 28x28. Each pixel represents a feature which means there are $28*28$ or $784$ features per each data sample.\n",
    "\n",
    "**The goal of the dataset is to classify each image of handwritten digits correctly!**\n",
    "\n",
    "The dataset consists of 3 splits:\n",
    "\n",
    "1. **Train**: Throughout this assignment you will be training your model using this data. There are approximately 44k training samples.\n",
    "2. **Validation**: You will then use this set to tune your model and evaluate its performance. There are approximately 12k training samples.\n",
    "3. **Test**: This split simulates real life data which we often don't have access to until the model is deployed. We have kept this split hidden from you and we will use it to judge the performance of your model on Autolab.\n",
    "\n",
    "You DO NOT have access to the Test set as it gonna be used for scoring. This will not prevent you to complete this assignment at all."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e3d1ded",
   "metadata": {},
   "source": [
    "# Design Machine Learning Models (TODO)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e80813e2",
   "metadata": {},
   "source": [
    "## Base Model\n",
    "Basic model structure, **don't change** this component."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "062f1282",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseModel(ABC):\n",
    "    \"\"\" Super class for ITCS Machine Learning Class\"\"\"\n",
    "\n",
    "    @abstractmethod\n",
    "    def fit(self, X, y):\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def predict(self, X):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74e318b4",
   "metadata": {},
   "source": [
    "## ClassificationModel \n",
    "Basic model structure, **don't change** this component."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "77815774",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassificationModel(BaseModel):\n",
    "    \"\"\"\n",
    "        Abstract class for classification \n",
    "        \n",
    "        Attributes\n",
    "        ==========\n",
    "    \"\"\"\n",
    "\n",
    "    # check if the matrix is 2-dimensional. if not, raise an exception    \n",
    "    def _check_matrix(self, mat, name):\n",
    "        if len(mat.shape) != 2:\n",
    "            raise ValueError(f\"Your matrix {name} shape is not 2D! Matrix {name} has the shape {mat.shape}\")\n",
    "        \n",
    "    ####################################################\n",
    "    #### abstract funcitons ############################\n",
    "    @abstractmethod\n",
    "    def fit(self, X: np.ndarray, y: np.ndarray):\n",
    "        \"\"\"\n",
    "            train classification model\n",
    "            \n",
    "            Args:\n",
    "                X:  Input data\n",
    "                \n",
    "                y:  targets/labels\n",
    "        \"\"\"        \n",
    "        pass\n",
    "    \n",
    "    @abstractmethod\n",
    "    def predict(self, X: np.ndarray):\n",
    "        \"\"\"\n",
    "            apply the learned model to input X\n",
    "            \n",
    "            parameters\n",
    "            ----------\n",
    "            X     2d array\n",
    "                  input data\n",
    "            \n",
    "        \"\"\"        \n",
    "        pass \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36d8f422",
   "metadata": {},
   "source": [
    "## TODO: Classification with Perceptron\n",
    "*Please complete the TODOs. *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3569194a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Perceptron(ClassificationModel):\n",
    "    \"\"\"\n",
    "        Performs Gaussian Naive Bayes\n",
    "    \n",
    "        attributes:\n",
    "            alpha: learning rate or step size used by gradient descent.\n",
    "                \n",
    "            epochs (int): Number of times data is used to update the weights `self.w`.\n",
    "                Each epoch means a data sample was used to update the weights at least\n",
    "                once.\n",
    "                \n",
    "            seed (int): Seed to be used for NumPy's RandomState class\n",
    "                or universal seed np.random.seed() function.\n",
    "            \n",
    "            batch_size (int): Mini-batch size used to determine the size of mini-batches\n",
    "                if mini-batch gradient descent is used.\n",
    "            \n",
    "            w (np.ndarray): NumPy array which stores the learned weights.\n",
    "    \"\"\"\n",
    "    def __init__(self, alpha: float, epochs: int = 1, seed: int = None):\n",
    "        ClassificationModel.__init__(self)\n",
    "        self.alpha = alpha\n",
    "        self.epochs = epochs\n",
    "        self.seed = seed\n",
    "        self.w = None\n",
    "        \n",
    "    def fit(self, X: np.ndarray, y: np.ndarray):\n",
    "        \"\"\" Train model to learn optimal weights when performing binary classification.\n",
    "        \n",
    "            Args:\n",
    "                X: Data \n",
    "                \n",
    "                y: Targets/labels\n",
    "                \n",
    "             TODO:\n",
    "                Finish this method by using Rosenblatt's Perceptron algorithm to learn\n",
    "                the best weights to classify the binary data. There is no need to\n",
    "                implement th pocket algorithm unless you choose to do so. Also, update \n",
    "                and store the learned weights into `self.w`.\n",
    "        \"\"\"\n",
    "        pass # TODO Replace this line with your code\n",
    "       \n",
    "   \n",
    "    def predict(self, X: np.ndarray):\n",
    "        \"\"\" Make predictions using the learned weights.\n",
    "        \n",
    "            Args:\n",
    "                X: Data \n",
    "\n",
    "            TODO:\n",
    "                Finish this method by adding code to make a prediction given the learned\n",
    "                weights `self.w`. Store the predicted labels into `y_hat`.\n",
    "        \"\"\"\n",
    "        # TODO Add code below\n",
    "        \n",
    "        y_hat = np.ones([len(X), 1]) # TODO Store predictions here by replacing np.ones()\n",
    "        # Makes sure predictions are given as a 2D array\n",
    "        return y_hat.reshape(-1, 1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f1d172e",
   "metadata": {},
   "source": [
    "## TODO: Classification with NaiveBayes\n",
    "*Please complete the TODOs. *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "db805928",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NaiveBayes(ClassificationModel):\n",
    "    \"\"\"\n",
    "        Performs Gaussian Naive Bayes\n",
    "    \n",
    "        attributes:\n",
    "            smoothing: smoothing hyperparameter used to prevent numerical instability and \n",
    "                divide by zero errors\n",
    "                \n",
    "            class_labels (np.ndarray or list): Unique labels for the passed data. This \n",
    "                should be set in the fit() method.\n",
    "            \n",
    "            priors (np.ndarray): NumPy array which stores the priors.\n",
    "            \n",
    "            log_priors (np.ndarray): NumPy array which stores the log of the priors and\n",
    "                used by the predict() method.\n",
    "            \n",
    "            means (np.ndarray): NumPy array of means used by the\n",
    "                log_gaussian_distribution() method to compute the log likelihoods\n",
    "            \n",
    "            stds (np.ndarray): NumPy array of standard deviations used by the\n",
    "                log_gaussian_distribution() method to compute the log likelihoods\n",
    "            \n",
    "    \"\"\"\n",
    "    def __init__(self, smoothing: float = 10e-3):\n",
    "        ClassificationModel.__init__(self)\n",
    "        self.smoothing = smoothing\n",
    "        # All class variables that need to be set somewhere within the below methods.\n",
    "        self.class_labels = None\n",
    "        self.priors = None\n",
    "        self.log_priors = None\n",
    "        self.means = None\n",
    "        self.stds = None\n",
    "\n",
    "    def log_gaussian_distribution(self, X: np.ndarray, mu: np.ndarray, std: np.ndarray) -> np.ndarray:\n",
    "        \"\"\" Computes the log of a value at a given point in a Gaussian distribution\n",
    "        \n",
    "            Args:\n",
    "                X: Data for which an output value is computed for.\n",
    "                \n",
    "                mu: Feature means\n",
    "                \n",
    "                var: Feature variance\n",
    "        \"\"\"\n",
    "        return norm.logpdf(X, mu, std**2)\n",
    "        \n",
    "    def compute_priors(self, y: np.ndarray) -> None:\n",
    "        \"\"\" Computes the priors and log priors for each class.\n",
    "    \n",
    "            Args:\n",
    "                y: Lables\n",
    "                \n",
    "            TODO: \n",
    "                Finish this method by computing the priors and log priors to be used when\n",
    "                making predictions using MAP. Store the computed priors and log priors \n",
    "                into self.priors and self.log_priors.\n",
    "                \n",
    "        \"\"\"\n",
    "        # TODO Add code below\n",
    "        \n",
    "        self.priors = None  # TODO Store priors here by replacing None\n",
    "        self.log_priors = None # TODO Store log priors here by replacing None\n",
    "    \n",
    "    def compute_parameters(self, X: np.ndarray, y: np.ndarray) -> None:\n",
    "        \"\"\" Computes the means and standard deviations for classes and features\n",
    "        \n",
    "            Args:\n",
    "                X: Data \n",
    "                \n",
    "                y: Targets/labels\n",
    "\n",
    "            TODO: \n",
    "                Finish this method by computing the means and stds for the Gaussian\n",
    "                distribution which will then be used to comput the likelihoods. Store\n",
    "                the computed means and stds into self.means and self.stds.\n",
    "        \"\"\"\n",
    "        # TODO Add code below\n",
    "        \n",
    "        self.means = None # TODO Store means here by replacing None\n",
    "        self.stds =  None # TODO Store stds here by replacing None\n",
    "        \n",
    "        # Add smoothing term to standrad deviation to \n",
    "        # help prevent numerical instability when STD equal\n",
    "        # or near 0.\n",
    "        self.stds += self.smoothing\n",
    "        \n",
    "    def compute_log_likelihoods(self, X: np.ndarray) -> np.ndarray:\n",
    "        \"\"\" Computes and returns log likelihoods using the means and stds\n",
    "                \n",
    "            Args:\n",
    "                X: Data \n",
    "        \n",
    "            TODO:\n",
    "                Finish this method by computing the log likelihoods of the passed data \n",
    "                `X`. Use the `self.means` and `self.stds` class variables you set in \n",
    "                the `compute_parameters()` method along with the `log_gaussian_distribution()` \n",
    "                method which is defined for you. The `log_gaussian_distribution()`  \n",
    "                will apply the log to your feature likelihoods for you so you don't need to!\n",
    "                This method should return the computed log likelihoods.\n",
    "        \"\"\"\n",
    "        pass # TODO Replace this line with your code\n",
    "        \n",
    "    def fit(self, X: np.ndarray, y: np.ndarray) -> None:\n",
    "        \"\"\" Computes the priors and Gaussian parameters used for predicting.\n",
    "        \n",
    "            Args:\n",
    "                X: Data \n",
    "                \n",
    "                y: Targets/labels\n",
    "                \n",
    "             TODO:\n",
    "                Finish this method by computing the priors and Gaussian parameters. \n",
    "                To do so, first finish and then call the compute_parameters() and \n",
    "                compute_priors() methods.\n",
    "        \"\"\"\n",
    "        self.class_labels = np.unique(y)\n",
    "        # TODO Add code below\n",
    "\n",
    "    def predict(self, X) -> np.ndarray:\n",
    "        \"\"\" Comptues a prediction using log likelihoods and log priors.\n",
    "        \n",
    "            Args:\n",
    "                X: Data \n",
    "        \n",
    "             TODO:\n",
    "                Finish this method by computing the log likelihoods and log priors.\n",
    "                To do so, first finishing and then call the compute_log_likelihoods() \n",
    "                method. You'll also need to access the class variables self.log_priors \n",
    "                and self.class_labels you set when running the fit(), compute_parameters() \n",
    "                and compute_priors() methods. Store the predicted labels into `y_hat`.\n",
    "        \"\"\"\n",
    "        # TODO Add code below\n",
    "\n",
    "        y_hat = np.ones([len(X), 1]) # TODO Store predictions here by replacing np.ones()\n",
    "        # Makes sure predictions are given as a 2D array\n",
    "        return y_hat.reshape(-1, 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f818005",
   "metadata": {},
   "source": [
    "## TODO: Classification with Logistic Regression\n",
    "*Please complete the TODOs. *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f0b2eef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegression(ClassificationModel):\n",
    "    \"\"\"\n",
    "        Performs Logistic Regression using the softmax function.\n",
    "    \n",
    "        attributes:\n",
    "            alpha: learning rate or step size used by gradient descent.\n",
    "                \n",
    "            epochs: Number of times data is used to update the weights `self.w`.\n",
    "                Each epoch means a data sample was used to update the weights at least\n",
    "                once.\n",
    "            \n",
    "            seed (int): Seed to be used for NumPy's RandomState class\n",
    "                or universal seed np.random.seed() function.\n",
    "            \n",
    "            batch_size: Mini-batch size used to determine the size of mini-batches\n",
    "                if mini-batch gradient descent is used.\n",
    "            \n",
    "            w (np.ndarray): NumPy array which stores the learned weights.\n",
    "    \"\"\"\n",
    "    def __init__(self, alpha: float, epochs: int = 1,  seed: int = None, batch_size: int = None):\n",
    "        ClassificationModel.__init__(self)\n",
    "        self.alpha = alpha\n",
    "        self.epochs = epochs\n",
    "        self.seed = seed\n",
    "        self.batch_size = batch_size\n",
    "        self.w = None\n",
    "\n",
    "    def softmax(self, z: np.ndarray) -> np.ndarray:\n",
    "        \"\"\" Computes probabilities for multi-class classification given continuous inputs z.\n",
    "        \n",
    "            Args:\n",
    "                z: Continuous outputs after dotting the data with the current weights \n",
    "\n",
    "            TODO:\n",
    "                Finish this method by adding code to return the softmax. Don't forget\n",
    "                to subtract the max from `z` to maintain  numerical stability!\n",
    "        \"\"\"\n",
    "        pass # TODO Replace this line with your code\n",
    "\n",
    "    def fit(self, X: np.ndarray, y: np.ndarray) -> None:\n",
    "        \"\"\" Train our model to learn optimal weights for classifying data.\n",
    "        \n",
    "            Args:\n",
    "                X: Data \n",
    "                \n",
    "                y: Targets/labels\n",
    "                \n",
    "             TODO:\n",
    "                Finish this method by using either batch or mini-batch gradient descent\n",
    "                to learn the best weights to classify the data. You'll need to finish and \n",
    "                also call the `softmax()` method to complete this method. Also, update \n",
    "                and store the learned weights into `self.w`. \n",
    "        \"\"\"\n",
    "        pass # TODO Replace this line with your code\n",
    "\n",
    "       \n",
    "    def predict(self, X: np.ndarray):\n",
    "        \"\"\" Make predictions using the learned weights.\n",
    "        \n",
    "            Args:\n",
    "                X: Data \n",
    "\n",
    "            TODO:\n",
    "                Finish this method by adding code to make a prediction given the learned\n",
    "                weights `self.w`. Store the predicted labels into `y_hat`.\n",
    "        \"\"\"\n",
    "        # TODO Add code below\n",
    "\n",
    "        y_hat = np.ones([len(X), 1])  # TODO Store predictions here by replacing np.ones()\n",
    "        # Makes sure predictions are given as a 2D array\n",
    "        return y_hat.reshape(-1, 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "287a9b61",
   "metadata": {},
   "source": [
    "# TODO: Define Hyperparameters \n",
    "*Please complete the TODOs. *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3b70d324",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HyperParametersAndTransforms():\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_params(name):\n",
    "        model = getattr(HyperParametersAndTransforms, name)\n",
    "        params = {}\n",
    "        for key, value in model.__dict__.items():\n",
    "            if not key.startswith('__') and not callable(key):\n",
    "                if not callable(value) and not isinstance(value, staticmethod):\n",
    "                    params[key] = value\n",
    "        return params\n",
    "    \n",
    "    class Perceptron():\n",
    "        \"\"\"Kwargs for classifier the Perceptron class and data prep\"\"\"\n",
    "        model_kwargs = dict(\n",
    "            alpha = None,  # TODO (REQUIRED) Set learning rate \n",
    "            epochs = 1,  # TODO (REQUIRED) Set epochs\n",
    "            seed = None, # TODO (OPTIONAL) Set seed for reproducible results\n",
    "        )\n",
    "\n",
    "        data_prep_kwargs = dict(\n",
    "            # TODO (OPTIONAL) Add Pipeline() definitions below\n",
    "            target_pipe = None,\n",
    "            # TODO (REQUIRED) Add Pipeline() definitions below\n",
    "            feature_pipe = None\n",
    "        )\n",
    "        \n",
    "    class NaiveBayes():\n",
    "        \"\"\"Kwargs for classifier the NaiveBayes class and data prep\"\"\"\n",
    "        model_kwargs = dict(\n",
    "            smoothing = 10e-2, # (OPTIONAL) TODO Set smoothing parameter for STD\n",
    "        )\n",
    "        \n",
    "        data_prep_kwargs = dict(\n",
    "            # TODO (OPTIONAL) Add Pipeline() definitions below\n",
    "            target_pipe = None,\n",
    "            # TODO (REQUIRED) Add Pipeline() definitions below\n",
    "            feature_pipe = None\n",
    "        )\n",
    "        \n",
    "    class LogisticRegression():\n",
    "        model_kwargs = dict(\n",
    "            alpha = None, # TODO (REQUIRED) Set learning rate\n",
    "            epochs = 1, # TODO (REQUIRED) Set epochs\n",
    "            seed = None, # TODO (OPTIONAL) Set seed for reproducible results\n",
    "            batch_size = None, # TODO (OPTIONAL) Set mini-batch size if using mini-batch gradient descent\n",
    "        )\n",
    "      \n",
    "        data_prep_kwargs = dict(\n",
    "            # TODO (REQUIRED) Add Pipeline() definitions below\n",
    "            target_pipe = None,\n",
    "            # TODO (REQUIRED) Add Pipeline() definitions below\n",
    "            feature_pipe = None\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87d8d604",
   "metadata": {},
   "source": [
    "# Model Training and Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a2383ff",
   "metadata": {},
   "source": [
    "## Define Preprocessing Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3a12fe70",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataPreparation():\n",
    "    def __init__(self, target_pipe, feature_pipe):\n",
    "        self.target_pipe = target_pipe\n",
    "        self.feature_pipe = feature_pipe\n",
    "        \n",
    "    @abstractmethod\n",
    "    def data_prep(self):\n",
    "        pass\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        if self.target_pipe  is not None:\n",
    "            self.target_pipe.fit(y)\n",
    "            \n",
    "        if self.feature_pipe is not None:\n",
    "            self.feature_pipe.fit(X)\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        if self.target_pipe is not None:\n",
    "            y = self.target_pipe.transform(y)\n",
    "            \n",
    "        if self.feature_pipe is not None:\n",
    "            X = self.feature_pipe.transform(X)\n",
    "\n",
    "        return X, y\n",
    "    \n",
    "    def fit_transform(self, X, y):\n",
    "        self.fit(X, y)\n",
    "        X, y = self.transform(X, y)\n",
    "        return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6d3eba0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNISTDataPreparation(DataPreparation):\n",
    "    def __init__(self, target_pipe, feature_pipe):\n",
    "        super().__init__(target_pipe, feature_pipe)\n",
    "        \n",
    "    def data_prep(self, binarize=False, return_array=False):\n",
    "        mnist_dataset = MNISTDataset()\n",
    "        X_trn_df, y_trn_df, X_vld_df, y_vld_df = mnist_dataset.load()\n",
    "        \n",
    "        # Converts MNIST problem to classifying ONLY 1s vs 0s\n",
    "        if binarize:\n",
    "            X_trn_df, y_trn_df = binarize_classes(\n",
    "                X_trn_df, \n",
    "                y_trn_df, \n",
    "                pos_class=[1],\n",
    "                neg_class=[0], \n",
    "            )\n",
    "            \n",
    "            X_vld_df, y_vld_df = binarize_classes(\n",
    "                X_vld_df, \n",
    "                y_vld_df, \n",
    "                pos_class=[1], \n",
    "                neg_class=[0], \n",
    "            )\n",
    "\n",
    "        X_trn_df, y_trn_df = self.fit_transform(X=X_trn_df, y=y_trn_df)\n",
    "        X_vld_df, y_vld_df = self.transform(X=X_vld_df, y=y_vld_df)\n",
    "\n",
    "        if return_array:\n",
    "            print(\"Returning data as NumPy array...\")\n",
    "            return dataframe_to_array([X_trn_df, y_trn_df, X_vld_df, y_vld_df])\n",
    "            \n",
    "        return X_trn_df, y_trn_df, X_vld_df, y_vld_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e98f14bc",
   "metadata": {},
   "source": [
    "## Define Model running (training/fit and testing/evaluate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "87e8beb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_name(obj):\n",
    "    try:\n",
    "        if hasattr(obj, '__name__'):\n",
    "            return obj.__name__\n",
    "        else:\n",
    "            return obj\n",
    "    except Exception as e:\n",
    "        return obj\n",
    "    \n",
    "def catch_and_throw(e, err):\n",
    "    trace = traceback.format_exc()\n",
    "    print(err + f\"\\n{trace}\")\n",
    "    raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7d468676",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RunModel():\n",
    "    t1 = '\\t'\n",
    "    t2 = '\\t\\t'\n",
    "    t3 = '\\t\\t\\t'\n",
    "    def __init__(self, model, model_params):\n",
    "        self.model_name = model.__name__\n",
    "        self.model_params = model_params\n",
    "        self.model = self.build_model(model, model_params)\n",
    "\n",
    "    def build_model(self, model, model_params):\n",
    "        print(\"=\"*50)\n",
    "        print(f\"Building model {self.model_name}\")\n",
    "        \n",
    "        try:\n",
    "            model = model(**model_params)\n",
    "        except Exception as e:\n",
    "            err = f\"Exception caught while building model for {self.model_name}:\"\n",
    "            catch_and_throw(e, err)\n",
    "        return model\n",
    "    \n",
    "    def fit(self, *args, **kwargs):\n",
    "        print(f\"Training {self.model_name}...\")\n",
    "        print(f\"{self.t1}Using hyperparameters: \")\n",
    "        [print(f\"{self.t2}{n} = {get_name(v)}\")for n, v in self.model_params.items()]\n",
    "        try: \n",
    "            return self._fit(*args, **kwargs)\n",
    "        except Exception as e:\n",
    "            err = f\"Exception caught while training model for {self.model_name}:\"\n",
    "            catch_and_throw(e, err)\n",
    "            \n",
    "    def _fit(self, X, y, metrics=None, pass_y=False):\n",
    "        if pass_y:\n",
    "            self.model.fit(X, y)\n",
    "        else:\n",
    "             self.model.fit(X)\n",
    "        preds = self.model.predict(X)\n",
    "        scores = self.get_metrics(y, preds, metrics, prefix='Train')\n",
    "        return scores\n",
    "    \n",
    "    def evaluate(self, *args, **kwargs):\n",
    "        print(f\"Evaluating {self.model_name}...\")\n",
    "        try:\n",
    "            return self._evaluate(*args, **kwargs)\n",
    "        except Exception as e:\n",
    "            err = f\"Exception caught while evaluating model for {self.model_name}:\"\n",
    "            catch_and_throw(e, err)\n",
    "        \n",
    "\n",
    "    def _evaluate(self, X, y, metrics, prefix=''):\n",
    "        preds = self.model.predict(X)\n",
    "        scores = self.get_metrics(y, preds, metrics, prefix)      \n",
    "        return scores\n",
    "    \n",
    "    def predict(self, X):\n",
    "        try:\n",
    "            preds = self.model.predict(X)\n",
    "        except Exception as e:\n",
    "            err = f\"Exception caught while making predictions for model {self.model_name}:\"\n",
    "            catch_and_throw(e, err)\n",
    "            \n",
    "        return preds\n",
    "    \n",
    "    def get_metrics(self, y, y_hat, metrics, prefix=''):\n",
    "        scores = {}\n",
    "        for name, metric in metrics.items():\n",
    "            score = metric(y, y_hat)\n",
    "            display_score = round(score, 3)\n",
    "            scores[name] = score\n",
    "            print(f\"{self.t2}{prefix} {name}: {display_score}\")\n",
    "        return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b6e0d05f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_eval(eval_stage='validation'):\n",
    "    main_timer = Timer()\n",
    "    main_timer.start()\n",
    "\n",
    "    total_points = 0\n",
    "    \n",
    "    task_info = [\n",
    "       dict(\n",
    "            model=Perceptron,\n",
    "            name='Perceptron',\n",
    "            data=MNISTDataPreparation,\n",
    "            data_prep=dict(binarize=True, return_array=True),\n",
    "            metrics=dict(acc=accuracy),\n",
    "            eval_metric='acc',\n",
    "            rubric=rubric_perceptron,\n",
    "            trn_score=0,\n",
    "            eval_score=0,\n",
    "            successful=False,\n",
    "        ),\n",
    "        dict(\n",
    "            model=NaiveBayes,\n",
    "            name='NaiveBayes',\n",
    "            data=MNISTDataPreparation,\n",
    "            data_prep=dict(return_array=True),\n",
    "            metrics=dict(acc=accuracy),\n",
    "            eval_metric='acc',\n",
    "            rubric=rubric_naive_bayes,\n",
    "            trn_score=0,\n",
    "            eval_score=0,\n",
    "            successful=False,\n",
    "        ),\n",
    "        dict(\n",
    "            model=LogisticRegression,\n",
    "            name='LogisticRegression',\n",
    "            data=MNISTDataPreparation,\n",
    "            data_prep=dict(return_array=True),\n",
    "            metrics=dict(acc=accuracy),\n",
    "            rubric=rubric_logistic_regression,\n",
    "            eval_metric='acc',\n",
    "            trn_score=0,\n",
    "            eval_score=0,\n",
    "            successful=False,\n",
    "        ),\n",
    "    ]\n",
    "    \n",
    "    total_points = 0\n",
    "    \n",
    "    for info in task_info:\n",
    "        task_timer =  Timer()\n",
    "        task_timer.start()\n",
    "        try:\n",
    "            params = HyperParametersAndTransforms.get_params(info['name'])\n",
    "            model_kwargs = params.get('model_kwargs', {})\n",
    "            data_prep_kwargs = params.get('data_prep_kwargs', {})\n",
    "            \n",
    "            run_model = RunModel(info['model'], model_kwargs)\n",
    "            data = info['data'](**data_prep_kwargs)\n",
    "            X_trn, y_trn, X_vld, y_vld = data.data_prep(**info['data_prep'])\n",
    "            \n",
    "            trn_scores = run_model.fit(X_trn, y_trn, info['metrics'], pass_y=True)\n",
    "            eval_scores = run_model.evaluate(X_vld, y_vld, info['metrics'], prefix=eval_stage.capitalize())\n",
    "            \n",
    "            info['trn_score'] = trn_scores[info['eval_metric']]\n",
    "            info['eval_score'] = eval_scores[info['eval_metric']]\n",
    "            info['successful'] = True\n",
    "                \n",
    "        except Exception as e:\n",
    "            track = traceback.format_exc()\n",
    "            print(\"The following exception occurred while executing this test case:\\n\", track)\n",
    "        task_timer.stop()\n",
    "        \n",
    "        print(\"\")\n",
    "        points = info['rubric'](info['eval_score'])\n",
    "        print(f\"Points Earned: {points}\")\n",
    "        total_points += points\n",
    "        \n",
    "    print(\"=\"*50)\n",
    "    print('')\n",
    "    main_timer.stop()\n",
    "    \n",
    "    avg_trn_acc, avg_eval_acc, successful_tests = summary(task_info)\n",
    "    task_eval_acc = get_eval_scores(task_info)\n",
    "    total_points = int(round(total_points))\n",
    "    \n",
    "    print(f\"Tests passed: {successful_tests}/{ len(task_info)}, Total Points: {total_points}/80\\n\")\n",
    "    print(f\"Average Train Accuracy: {avg_trn_acc}\")\n",
    "    print(f\"Average {eval_stage.capitalize()} Accuracy: {avg_eval_acc}\")\n",
    "    \n",
    "    return (total_points, avg_eval_acc, main_timer.last_elapsed_time, avg_trn_acc, *task_eval_acc)\n",
    "\n",
    "def summary(task_info):\n",
    "    sum_trn_acc = 0\n",
    "    sum_eval_acc = 0\n",
    "    successful_tests = 0\n",
    "\n",
    "    for info in task_info:\n",
    "        if info['successful']:\n",
    "            successful_tests += 1\n",
    "            sum_trn_acc += info['trn_score']\n",
    "            sum_eval_acc += info['eval_score']\n",
    "    \n",
    "    if successful_tests == 0:\n",
    "        return 0, 0, successful_tests\n",
    "    \n",
    "    avg_trn_acc = sum_trn_acc / len(task_info)\n",
    "    avg_eval_acc = sum_eval_acc / len(task_info)\n",
    "    return round(avg_trn_acc, 4), round(avg_eval_acc, 4), successful_tests\n",
    "\n",
    "def get_eval_scores(task_info):\n",
    "    return [i['eval_score'] for i in task_info]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5884c9b",
   "metadata": {},
   "source": [
    "## Evaluation Related Functions\n",
    "Don't change this section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0b5242ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rubric_perceptron(acc, max_score=25):\n",
    "    score_percent = 0\n",
    "    if acc >= 0.95:\n",
    "        score_percent = 100\n",
    "    elif acc >= 0.90:\n",
    "        score_percent = 90\n",
    "    elif acc >= 0.80:\n",
    "        score_percent = 80\n",
    "    elif acc >= 0.70:\n",
    "        score_percent = 70\n",
    "    elif acc >= 0.60:\n",
    "        score_percent = 60\n",
    "    elif acc >= 0.50:\n",
    "        score_percent = 50\n",
    "    else:\n",
    "        score_percent = 40\n",
    "    score = max_score * score_percent / 100.0 \n",
    "    return score\n",
    "\n",
    "def rubric_naive_bayes(acc, max_score=25):\n",
    "    score_percent = 0\n",
    "    if acc >= 0.75:\n",
    "        score_percent = 100\n",
    "    elif acc >= 0.65:\n",
    "        score_percent = 90\n",
    "    elif acc >= 0.55:\n",
    "        score_percent = 80\n",
    "    elif acc >= 0.40:\n",
    "        score_percent = 70\n",
    "    elif acc >= 0.30:\n",
    "        score_percent = 60\n",
    "    elif acc >= 0.20:\n",
    "        score_percent = 50\n",
    "    elif acc >= 0.10:\n",
    "        score_percent = 45\n",
    "    else:\n",
    "        score_percent = 40\n",
    "    score = max_score * score_percent / 100.0 \n",
    "    return score\n",
    "   \n",
    "def rubric_logistic_regression(acc, max_score=30):\n",
    "    score_percent = 0\n",
    "    if acc >= 0.85:\n",
    "        score_percent = 100\n",
    "    elif acc >= 0.80:\n",
    "        score_percent = 90\n",
    "    elif acc >= 0.75:\n",
    "        score_percent = 80\n",
    "    elif acc >= 0.70:\n",
    "        score_percent = 70\n",
    "    elif acc >= 0.60:\n",
    "        score_percent = 60\n",
    "    elif acc >= 0.50:\n",
    "        score_percent = 55\n",
    "    elif acc >= 0.40:\n",
    "        score_percent = 50\n",
    "    elif acc >= 0.30:\n",
    "        score_percent = 45\n",
    "    else:\n",
    "        score_percent = 40\n",
    "    score = max_score * score_percent / 100.0 \n",
    "    return score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8fdd04d",
   "metadata": {},
   "source": [
    "# Test your code\n",
    "Run the following cell to test your code (or for **debugging**)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "88c97211",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "Building model Perceptron\n",
      "Dowloading from url:  https://drive.google.com/uc?export=download&id=1PepMZ-2uHWf0HO-PG9we03jJ46BRHNUJ\n",
      "Saving to directory:  /Users/hunglinh/Desktop/Classification Mini Project/datasets/data/MNIST\n",
      "100% [......................................................] 9947427 / 9947427Download complete.\n",
      "\n",
      "Unzipping: /Users/hunglinh/Desktop/Classification Mini Project/datasets/data/MNIST/train.zip\n",
      "\n",
      "Dowloading from url:  https://drive.google.com/uc?export=download&id=1ER4qAUWncgZLSfGL_-hKmMqhFbUaImYt\n",
      "Saving to directory:  /Users/hunglinh/Desktop/Classification Mini Project/datasets/data/MNIST\n",
      "100% [......................................................] 2486540 / 2486540Download complete.\n",
      "\n",
      "Unzipping: /Users/hunglinh/Desktop/Classification Mini Project/datasets/data/MNIST/val.zip\n",
      "\n",
      "Loading dataset with Pandas...\n",
      "Done!\n",
      "Returning data as NumPy array...\n",
      "Training Perceptron...\n",
      "\tUsing hyperparameters: \n",
      "\t\talpha = None\n",
      "\t\tepochs = 1\n",
      "\t\tseed = None\n",
      "\t\tTrain acc: 0.53\n",
      "Evaluating Perceptron...\n",
      "\t\tValidation acc: 0.531\n",
      "Elapsed time: 13.9681 seconds\n",
      "\n",
      "Points Earned: 12.5\n",
      "==================================================\n",
      "Building model NaiveBayes\n",
      "Skipping download. File already exists: /Users/hunglinh/Desktop/Classification Mini Project/datasets/data/MNIST/train.zip\n",
      "\n",
      "Unzipping: /Users/hunglinh/Desktop/Classification Mini Project/datasets/data/MNIST/train.zip\n",
      "\n",
      "Skipping download. File already exists: /Users/hunglinh/Desktop/Classification Mini Project/datasets/data/MNIST/val.zip\n",
      "\n",
      "Unzipping: /Users/hunglinh/Desktop/Classification Mini Project/datasets/data/MNIST/val.zip\n",
      "\n",
      "Loading dataset with Pandas...\n",
      "Done!\n",
      "Returning data as NumPy array...\n",
      "Training NaiveBayes...\n",
      "\tUsing hyperparameters: \n",
      "\t\tsmoothing = 0.1\n",
      "\t\tTrain acc: 0.112\n",
      "Evaluating NaiveBayes...\n",
      "\t\tValidation acc: 0.114\n",
      "Elapsed time: 2.8419 seconds\n",
      "\n",
      "Points Earned: 11.25\n",
      "==================================================\n",
      "Building model LogisticRegression\n",
      "Skipping download. File already exists: /Users/hunglinh/Desktop/Classification Mini Project/datasets/data/MNIST/train.zip\n",
      "\n",
      "Unzipping: /Users/hunglinh/Desktop/Classification Mini Project/datasets/data/MNIST/train.zip\n",
      "\n",
      "Skipping download. File already exists: /Users/hunglinh/Desktop/Classification Mini Project/datasets/data/MNIST/val.zip\n",
      "\n",
      "Unzipping: /Users/hunglinh/Desktop/Classification Mini Project/datasets/data/MNIST/val.zip\n",
      "\n",
      "Loading dataset with Pandas...\n",
      "Done!\n",
      "Returning data as NumPy array...\n",
      "Training LogisticRegression...\n",
      "\tUsing hyperparameters: \n",
      "\t\talpha = None\n",
      "\t\tepochs = 1\n",
      "\t\tseed = None\n",
      "\t\tbatch_size = None\n",
      "\t\tTrain acc: 0.112\n",
      "Evaluating LogisticRegression...\n",
      "\t\tValidation acc: 0.114\n",
      "Elapsed time: 3.0023 seconds\n",
      "\n",
      "Points Earned: 12.0\n",
      "==================================================\n",
      "\n",
      "Elapsed time: 19.8125 seconds\n",
      "Tests passed: 3/3, Total Points: 36/80\n",
      "\n",
      "Average Train Accuracy: 0.2512\n",
      "Average Validation Accuracy: 0.2528\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    run_eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc5fb513",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7993788d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
